# -*- coding: utf-8 -*-
"""RAGService.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10wk36f3TX-_fkBQpCoDxyyy10BBVUs2D
"""

!pip install chromadb

!pip install -U langchain-community
#!pip install -U langchain-community
#!pip install faiss-cpu
#!pip install chromadb

from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import Chroma
from langchain.text_splitter import CharacterTextSplitter
from langchain.document_loaders import TextLoader, WebBaseLoader
from langchain.chains import RetrievalQA
from langchain.vectorstores import FAISS
from langchain.llms import HuggingFacePipeline
from transformers import AutoModelForCausalLM, AutoTokenizer
from transformers import pipeline

# loading from two sources
loader = TextLoader("/content/drive/MyDrive/lab/dataset/mental_health.txt")
txt_documents_1 = loader.load()
# web_loader = WebBaseLoader("https://pmc.ncbi.nlm.nih.gov/articles/PMC9902068/")
# web_documents = web_loader.load()
# documents = txt_documents + web_documents

loader = TextLoader("/content/drive/MyDrive/lab/dataset/health_blog.txt")
txt_documents_2 = loader.load()
documents = txt_documents_1 + txt_documents_2

text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=50)
docs = text_splitter.split_documents(documents)
#RecursiveCharacterTextSplitter for production workloads

print(docs)

embedding_model = HuggingFaceEmbeddings(model_name="BAAI/bge-small-en-v1.5")

vectorstore = Chroma.from_documents(docs, embedding_model)

# #Can use FAISS if need persistence
# vectorstore = FAISS.from_documents(docs, embedding_model)
# vectorstore.save_local("/content/drive/MyDrive/lab/faiss_index")
# # can load from local
# vectorstore = FAISS.load_local(
#     "/content/drive/MyDrive/lab/faiss_index",
#     embedding_model,
#     allow_dangerous_deserialization=True
# )

model_name = "TinyLlama/TinyLlama-1.1B-Chat-v1.0"

#Invoking pipeline object for generating text responses.
qa_pipeline = pipeline(
    "text-generation",
    model=model_name,
    max_new_tokens=200,
    temperature=0.7,
    device_map="auto"
)

llm = HuggingFacePipeline(pipeline=qa_pipeline)

qa = RetrievalQA.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever(search_type="similarity"),
    chain_type="stuff"
)
# retriever Decide which documents to pull
# By default, it just finds the top-k most similar documents by cosine similarity.
# chain_type="stuff". simple. other options - refine, map_reduce

# Retrieve with Sources
from langchain.chains import RetrievalQAWithSourcesChain
qa = RetrievalQAWithSourcesChain.from_chain_type(
    llm=llm,
    retriever=vectorstore.as_retriever()
)
query = "Which type of exercise was more effective for anxiety reduction?"
result = qa({"question": query})
print("Answer:", result["answer"])
print("Sources:", result["sources"])

query = "What does the document say about ?"
result = qa.run(query)
print(result)

query = "Which type of exercise was more effective for anxiety reduction? ?"
result = qa.run(query)
print(result)

# Result with Score
query = "Which type of exercise was more effective for anxiety reduction? ?"
query_embedding = embedding_model.embed_query(query)
docs_with_scores = vectorstore.as_retriever().get_relevant_documents(query)
doc_embeddings = [embedding_model.embed_query(d.page_content) for d in docs_with_scores]

scores = cosine_similarity([query_embedding], doc_embeddings)[0]


result = qa.run(query)

print("\nLLM Answer:  ")
print(result)

for doc, score in zip(docs_with_scores, scores):
    print(f"Score: {score:.3f} | Content: {doc.page_content[:300]}...")

#Embedding Visualization
import numpy as np
import pandas as pd
from sklearn.manifold import TSNE
import plotly.express as px


doc_texts = [d.page_content for d in docs]
doc_embeddings = embedding_model.embed_documents(doc_texts)
X = np.array(doc_embeddings)

tsne = TSNE(n_components=2, random_state=42, perplexity=3)
X_2d = tsne.fit_transform(X)


data = pd.DataFrame({
    "x": X_2d[:,0],
    "y": X_2d[:,1],
    "text": [doc.page_content[:300] for doc in docs],
    "section": [doc.metadata.get("section", "Unknown") for doc in docs]
})

# Plot with Plotly
fig = px.scatter(
    data, x="x", y="y",
    color="section",
    hover_data={"text": True},
    title="t-SNE Visualization of Document Embeddings"
)

fig.show()

from sklearn.manifold import TSNE
import matplotlib.pyplot as plt
import numpy as np

#Embeddings for each document chunk
doc_texts = [d.page_content for d in docs]
doc_embeddings = embedding_model.embed_documents(doc_texts)
np_doc_embeddings = np.array(doc_embeddings)
# # Reduce dimensions for visualization
tsne = TSNE(n_components=2, random_state=42, perplexity=2)
reduced_embeddings = tsne.fit_transform(np_doc_embeddings)

# # Plot
plt.figure(figsize=(10,6))
plt.scatter(reduced_embeddings[:,0], reduced_embeddings[:,1], c="blue")
for i, txt in enumerate(doc_texts[:20]):  # label a few chunks
    plt.annotate(txt[:20] + "...", (reduced_embeddings[i,0], reduced_embeddings[i,1]))
plt.title("t-SNE visualization of document embeddings")
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

# Compute similarity matrix (cosine similarity)
from sklearn.metrics.pairwise import cosine_similarity
sim_matrix = cosine_similarity(np_doc_embeddings)

# Plot heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(sim_matrix, cmap="viridis")
plt.title("Embedding Similarity Heatmap")
plt.show()

!pip install -U mcp

# can wrap this RAG as a MCP Provider
from mcp.server import Server
from mcp.server import Server, tool

retriever = vectorstore.as_retriever()

server = Server("rag-provider")

@tool
async def retrieve_answer(query: str) -> str:
    """
    Retrieve an answer from the RAG pipeline.
    """
    return qa.run(query)

@tool
async def retrieve_chunks(query: str) -> dict:
    """
    Retrieve relevant chunks with similarity scores.
    """
    docs = retriever.get_relevant_documents(query)
    results = [
        {"content": d.page_content, "metadata": d.metadata}
        for d in docs
    ]
    return {"query": query, "results": results}

if __name__ == "__main__":
    server.run()

'''
 Example Questions You Can Ask RAG

General comprehension

What was the main finding of the research paper?

How many studies were included in the review?

Specific detail

Which neurotransmitters are influenced by exercise according to the paper?

What percentage reduction in depressive symptoms was observed?

Comparison

Which type of exercise was more effective for anxiety reduction?

How did aerobic exercise compare with resistance training?

Implications

Why do the authors recommend including exercise in treatment guidelines?

How is exercise considered a cost-effective therapy?

Critical thinking

What are the limitations of using exercise as a treatment for mental health disorders?

What further research could build on these findings? '''

